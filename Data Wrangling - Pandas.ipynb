{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1334cd8d",
   "metadata": {
    "id": "1334cd8d"
   },
   "source": [
    "pandas: https://pandas.pydata.org/docs/user_guide/index.html#user-guide\n",
    "\n",
    "pandas DF: https://pandas.pydata.org/docs/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98ede6",
   "metadata": {
    "id": "9b98ede6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a273824d",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    " # Table of Contents  \n",
    "1. [Options](#options)\n",
    "    1. A\n",
    "    1. B\n",
    "1. [String](#string)\n",
    "1. [Dates](#dates)\n",
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795434f",
   "metadata": {
    "id": "9795434f"
   },
   "source": [
    "<a id=\"options\"></a> \n",
    "# ---------- Options ----------\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99b545",
   "metadata": {
    "id": "1f99b545"
   },
   "outputs": [],
   "source": [
    "## describe all options\n",
    "pd.describe_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c1238",
   "metadata": {
    "id": "a09c1238"
   },
   "outputs": [],
   "source": [
    "## show the current value of an option\n",
    "pd.options.display.max_rows\n",
    "# .max_rows(None) .max_columns(None) .precision(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41190c29",
   "metadata": {
    "id": "41190c29"
   },
   "outputs": [],
   "source": [
    "## set an option\n",
    "pd.set_option(\"display.max_rows\", 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091cb00",
   "metadata": {
    "id": "5091cb00"
   },
   "source": [
    "<a id=\"string\"></a> \n",
    "# ---------- String ----------\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32d682",
   "metadata": {
    "id": "6c32d682"
   },
   "source": [
    "## Series.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800282d",
   "metadata": {
    "id": "6800282d"
   },
   "outputs": [],
   "source": [
    "# basic\n",
    "# .lower() .upper() .len() .strip() .lstrip() .rstrip() .repeat() .pad()\n",
    "# .isalpha() .isdigit() .islower() .replace\n",
    "string_series.str.strip()\n",
    "string_series.str.replace(pat=' ', repl='-', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e0dbb",
   "metadata": {
    "id": "c54e0dbb",
    "outputId": "c943cb38-2ce1-4151-991b-19fa0101524a"
   },
   "outputs": [],
   "source": [
    "# .split(' ') .split().str[1] .split('', expand=True, n=2)\n",
    "string_series.str.split('', expand=True, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a849c2c",
   "metadata": {
    "id": "8a849c2c"
   },
   "outputs": [],
   "source": [
    "# extract named groups -> one column per group\n",
    "string_series.str.extract(r\"(?P<letter>[ab])(?P<digit>\\d)\")\n",
    "\n",
    "# concatenate series into one string\n",
    "string_series.str.cat(sep=',', na_rep='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcd694b",
   "metadata": {
    "id": "fbcd694b",
    "outputId": "4f6cd4d9-75be-44da-9b9b-70c445860b4e"
   },
   "outputs": [],
   "source": [
    "string_series.str.cat(['a','b','c','d'], sep='_', na_rep='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d3e9ff",
   "metadata": {
    "id": "f2d3e9ff",
    "outputId": "7d63e39e-6f74-4627-f8f2-ede1cbdd5a4c"
   },
   "outputs": [],
   "source": [
    "# concatenate with a dataframe of strings\n",
    "# based on index\n",
    "new = pd.DataFrame([['a','b','c','d'], [1,2,3,4]], dtype='string').T\n",
    "new.set_axis([1,2,3,4], axis=0, inplace=True)\n",
    "string_series.str.cat(new, sep='_', na_rep='', join='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06452386",
   "metadata": {
    "id": "06452386"
   },
   "source": [
    "<a id=\"dates\"></a>\n",
    "# ---------- Dates ----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b04d65",
   "metadata": {
    "id": "34b04d65"
   },
   "source": [
    "## pd.to_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7cc67",
   "metadata": {
    "id": "b3c7cc67",
    "outputId": "adcd3b82-9068-44a8-c4ed-ee1763ec38dd"
   },
   "outputs": [],
   "source": [
    "pd.to_datetime('today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0766d54",
   "metadata": {
    "id": "d0766d54",
    "outputId": "8d8dab78-5716-4dce-ddc0-944aac32e0bd"
   },
   "outputs": [],
   "source": [
    "# %a - abbreviated weekday name | %A - full weekday name\n",
    "# %d - day of month zero padded\n",
    "# %b - abbreviated month name | %B - full month name\n",
    "# %m - month zero padded\n",
    "# %y - year without century zero padded | %Y - year with centure\n",
    "datetime_index = pd.to_datetime(['26-03-1997', '20-04-1998'], format=\"%d-%m-%Y\")\n",
    "datetime_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b832031",
   "metadata": {
    "id": "8b832031"
   },
   "source": [
    "## pd.date_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154a878",
   "metadata": {
    "id": "c154a878",
    "outputId": "f18e5bfe-4e77-4da3-d645-40fedcbce7c2"
   },
   "outputs": [],
   "source": [
    "# freq: '6H', 'D', 'M'\n",
    "datetime_index = pd.date_range(start='2020-01-01', periods=4, freq='M')\n",
    "datetime_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef76b56",
   "metadata": {
    "id": "6ef76b56"
   },
   "source": [
    "## Series.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621a6f2",
   "metadata": {
    "id": "8621a6f2",
    "outputId": "7d170f6c-46a6-4489-87eb-6b466b4bc609"
   },
   "outputs": [],
   "source": [
    "dt_series = datetime_index.to_series().reset_index(drop=True)\n",
    "\n",
    "# second, minute, hour,\n",
    "# day, dayofweek, dayofyear, day_name(), week, weekofyear, month, month_name(), quarter, year\n",
    "A = dt_series.dt.month_name().rename(\"month_name()\")\n",
    "\n",
    "# D, M, Q, Y\n",
    "B = dt_series.dt.to_period('Q').rename(\"to_period('Q')\")\n",
    "\n",
    "C = dt_series.dt.strftime('%d/%m/%Y').rename(\"strftime('%d/%m/%Y')\")\n",
    "\n",
    "D = dt_series.dt.tz_localize('EST').rename(\"tz_localize('EST')\")\n",
    "\n",
    "E = dt_series.dt.tz_localize('EST').dt.tz_convert('US/Pacific').rename(\"tz_convert('US/Pacific')\")\n",
    "\n",
    "pd.concat([dt_series, A, B, C, D, E], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e98ec3c",
   "metadata": {
    "id": "7e98ec3c"
   },
   "source": [
    "## Time Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27df3fa",
   "metadata": {
    "id": "c27df3fa",
    "outputId": "22a6fe5f-2ff6-42f6-fd07-efce5c8c1d5d"
   },
   "outputs": [],
   "source": [
    "# difference between two dates\n",
    "time_delta = pd.to_datetime(\"2020/03/24 00:18:48\") - pd.to_datetime(\"2019/03/04 00:12:23\")\n",
    "time_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2dca0",
   "metadata": {
    "id": "40b2dca0",
    "outputId": "a338a985-0e04-41f1-e0d6-531cff037abf"
   },
   "outputs": [],
   "source": [
    "# extract time component from difference\n",
    "time_delta.days # microseeconds, seconds, total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a0c6d",
   "metadata": {
    "id": "af7a0c6d",
    "outputId": "fe16c3c3-5d1a-48c4-fa79-e7ea85f8f5ea"
   },
   "outputs": [],
   "source": [
    "# subtract date by time\n",
    "# weeks, days, hours, minutes, seconds, milliseconds, microseconds, nanoseconds\n",
    "pd.to_datetime(\"2020/03/24 00:18:48\") - pd.Timedelta(days=9, weeks=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e83035",
   "metadata": {
    "id": "58e83035"
   },
   "source": [
    "# ---------- Create Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec8da1",
   "metadata": {
    "id": "eeec8da1"
   },
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1c06c",
   "metadata": {
    "id": "78e1c06c"
   },
   "outputs": [],
   "source": [
    "# from dictionary\n",
    "pd.DataFrame({'col1': [10,20], 'col2': ['a','b']}, index=[1,2])\n",
    "\n",
    "# from nested list\n",
    "pd.DataFrame([[1,2,3], ['a','b','c']], index=[1,2], columns=['col1', 'col2', 'col3'])\n",
    "\n",
    "# from list of dictionaries\n",
    "pd.DataFrame([{'col1': 1, 'col2': 2}, {'col1': 1, 'col3': 3}], index=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843e788e",
   "metadata": {
    "id": "843e788e"
   },
   "source": [
    "## MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9f5c0",
   "metadata": {
    "id": "c7f9f5c0"
   },
   "outputs": [],
   "source": [
    "# tuples\n",
    "pd.MultiIndex.from_tuples([('a', '1'), ('a', '2'), ('b', '1'), ('b', '2')],\n",
    "                          names=[\"letter\", \"number\"])\n",
    "\n",
    "# cartesian product\n",
    "pd.MultiIndex.from_product([['a', 'b', 'c'], ['1', '2']],\n",
    "                           names=[\"letter\", \"number\"])\n",
    "\n",
    "# slice multi-index\n",
    "df.loc[('a', '1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8471449",
   "metadata": {
    "id": "a8471449"
   },
   "source": [
    "## Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35218520",
   "metadata": {
    "id": "35218520"
   },
   "source": [
    "### Series.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec211ca",
   "metadata": {
    "id": "cec211ca",
    "outputId": "1ba51104-65d2-4b3b-ff1f-f4ff87348c93"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'level': ['b', 'c', 'a']}) # column as string\n",
    "df['level'] = df['level'].astype('category') # convert column to category\n",
    "df['level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4de13",
   "metadata": {
    "id": "bae4de13",
    "outputId": "ac2619ba-58c6-40ec-9de6-087f48aa4b52"
   },
   "outputs": [],
   "source": [
    "df['level'].cat.categories = ['excellent', 'good', 'bad'] # reassign categories\n",
    "df['level'].cat.rename_categories({'excellent': 'great'}, inplace=True) # selective rename\n",
    "df['level'] = df['level'].cat.set_categories(['bad', 'good', 'great'], ordered=True) # specify category order\n",
    "df['level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf7a311",
   "metadata": {
    "id": "2cf7a311",
    "outputId": "5b909dc1-cfc0-4817-c5f8-a7ab1b93e24e"
   },
   "outputs": [],
   "source": [
    "df['level'].cat.reorder_categories(['great', 'good', 'bad'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59182e",
   "metadata": {
    "id": "ed59182e"
   },
   "outputs": [],
   "source": [
    "# .remove_unused_categories()\n",
    "# .remove_categories(['cat1', 'cat2'])\n",
    "# .as_ordered()\n",
    "# .as_unordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32f8d9",
   "metadata": {
    "id": "1f32f8d9"
   },
   "source": [
    "# ---------- Input / Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256a5a2",
   "metadata": {
    "id": "5256a5a2"
   },
   "outputs": [],
   "source": [
    "path = (\"C:/Users/mushj/Desktop/WORK/\"\n",
    "        \"Master of Management Analytics/\"\n",
    "        \"RSM8502H - Data-Based Management Decisions/\"\n",
    "        \"Group Assignment/\")\n",
    "\n",
    "# read table\n",
    "data = pd.read_table(path + \"bank-additional-full-1.csv\",\n",
    "                     header=3, sep=',', nrows=-1)\n",
    "\n",
    "# .xlsx files\n",
    "data = pd.read_excel(path + \"bank-additional-full-1.csv\",\n",
    "                     header=3, sheet_name='sheet_name or #')\n",
    "\n",
    "data = pd.read_csv(path + \"bank-additional-full-1.csv\",\n",
    "                   sep=';', delim_whitespace=False)\n",
    "\n",
    "# writing\n",
    "data.to_csv(\"filename.csv\", index=False)\n",
    "data.to_excel(\"filename.xlsx\")\n",
    "data.to_sql(\"filename.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f93438b",
   "metadata": {
    "id": "3f93438b"
   },
   "source": [
    "# ---------- Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0879160",
   "metadata": {
    "id": "d0879160"
   },
   "outputs": [],
   "source": [
    "data.shape\n",
    "data.columns.values\n",
    "data.index.values\n",
    "data.dtypes\n",
    "data.head(n=5)\n",
    "data.tail(n=5)\n",
    "data.info()\n",
    "\n",
    "# use .equals to compare df with np.nan, as np.nan != np.nan\n",
    "(data * 2).equals(data + data)\n",
    "\n",
    "# descriptive overview with custom percentiles\n",
    "data.describe(percentiles=[0.05, 0.1, 0.25], include=['float64'])\n",
    "\n",
    "# get unique values of column\n",
    "data['colnmae'].nunique()\n",
    "data['colname'].unique()\n",
    "\n",
    "data.duplicated(subset=['colname1', 'colname2'], keep=False) # keep: first, last\n",
    "\n",
    "# count value by group\n",
    "# add .to_frame(name='colname') to format as DataFrame\n",
    "data.value_counts([\"colname1\", \"colname2\", \"colname3\"],\n",
    "                  normalize=False sort=True, ascending=False)\n",
    "\n",
    "# print value counts for all object variables\n",
    "for col in data.columns.values:\n",
    "    if data[col].dtypes == 'object':\n",
    "        print(data.value_counts(col))\n",
    "        print('\\n')\n",
    "\n",
    "# check NaNs\n",
    "# axis=0 -> sum across rows, for each column\n",
    "data.isnull().sum(axis=0)\n",
    "data.notnull().sum(axis=0)\n",
    "data.isna().sum(axis=0)\n",
    "data.notna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd5097",
   "metadata": {
    "id": "56dd5097"
   },
   "source": [
    "# ---------- Math/Stat Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead641f",
   "metadata": {
    "id": "8ead641f"
   },
   "outputs": [],
   "source": [
    "# --- descriptive statistics\n",
    "# Dataframe & Series:\n",
    "# .count() .sum() .mean() .mad() .median() .min() .max() .mode()\n",
    "# .abs() .prod() .std() .var() .sem() .skew() .kurt() .quantile(0.75)\n",
    "# .cumsum() .cumprod() .cummin() .cummax()\n",
    "# .pct_change(periods=1)\n",
    "# data['colname1'].cov(data['colname2'])  data.cov()  | .corr(method='')\n",
    "\n",
    "# standard error of mean\n",
    "data.sem(axis=0, numeric_only=True, skipna=True)\n",
    "\n",
    "# Series:\n",
    "# .autocorr(lag=1)\n",
    "data['colname'].autocorr(lag=5)\n",
    "\n",
    "# --- arithmetic\n",
    "# .add() .sub() .mul() .div() .floordiv() .mod() .pow()\n",
    "data.sub([1, 2, 3], axis=1, fill_value=None) # broadcast rowwise\n",
    "\n",
    "# Dataframe & Series\n",
    "# closed: left, right, both, neither\n",
    "data.rolling(window=4, center=False, closed=None).mean()\n",
    "# rolling with custom function: Mean Absolute Deviation from mean within window\n",
    "data.rolling(window=4).apply(lambda x: np.abs(x - x.mean()).mean())\n",
    "\n",
    "# get index of min/max\n",
    "# .idxmin()\n",
    "data.idxmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68f146",
   "metadata": {
    "id": "7e68f146"
   },
   "outputs": [],
   "source": [
    "# correlation matrix: get corrs > 0.7\n",
    "cor_mat = data.corr()\n",
    "pairs = cor_mat.unstack().sort_values(ascending=False)\n",
    "pairs_cleaned = pairs[[i[0] != i[1] for i in pairs.index]].drop_duplicates() # remove self-corr and symmetry\n",
    "pairs_cleaned[pairs_cleaned > 0.7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ce1b5",
   "metadata": {
    "id": "3b6ce1b5"
   },
   "source": [
    "# ---------- Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d7e7e",
   "metadata": {
    "id": "3b3d7e7e"
   },
   "outputs": [],
   "source": [
    "# rename columns\n",
    "data.columns = ['newcolname1', 'newcolname2', 'newcolname3']\n",
    "\n",
    "# rename selected columns\n",
    "data.rename(columns={'oldcolname1': 'newcolname1', 'oldcolname2': 'newcolname2'},\n",
    "            index={'oldrowname': 'newrowname'})\n",
    "\n",
    "# add new index\n",
    "new_ind = data.index.union(pd.Index([3,4,5,6]))\n",
    "data.reindex(new_ind)\n",
    "\n",
    "# reset index; drop=True -> don't keep index as column\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# set a certain variable as index\n",
    "data.set_index(keys='varname', drop=True)\n",
    "\n",
    "# label axis names with list object, axis=0 (row names), axis=1 (colnames)\n",
    "data.set_axis(labels=['a', 'b', 'c'], axis=1)\n",
    "\n",
    "# name series before concatenating to dataframe\n",
    "pd.Series(new_col, name='new_colname')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f6dfd9",
   "metadata": {
    "id": "94f6dfd9"
   },
   "source": [
    "# ---------- Type / Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e7d71",
   "metadata": {
    "id": "f86e7d71"
   },
   "outputs": [],
   "source": [
    "data.astype(int) # change entire dataset: int, string\n",
    "data.astype({'colname1': 'float32', 'colname2': 'str'})\n",
    "\n",
    "pd.to_numeric(x, errors='coerce')\n",
    "\n",
    "data['colname1'].to_numpy() # to_series(), to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e351f",
   "metadata": {
    "id": "eb8e351f",
    "outputId": "b32e5962-1ec1-44fc-8503-af1ec0392b65"
   },
   "outputs": [],
   "source": [
    "# .astype('string') changes np.nan to pd.NA\n",
    "df = pd.DataFrame([[1.0, 1, pd.NA, np.nan]])\n",
    "df.astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b26472",
   "metadata": {
    "id": "f7b26472",
    "outputId": "d64b0e0d-fc0b-4b61-8132-b358939653b9"
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(type(df.astype('string').loc[:,i].values[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846126",
   "metadata": {
    "id": "dd846126"
   },
   "source": [
    "# ---------- Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce490e2c",
   "metadata": {
    "id": "ce490e2c"
   },
   "outputs": [],
   "source": [
    "# reorder dataframe based on new index order\n",
    "data.reindex([4, 2, 1, 3], axis=0)\n",
    "data.reindex(index=[4, 2, 1, 3], columns=['A', 'B', 'C'])\n",
    "\n",
    "# if there are new indexes, fill with\n",
    "# ffill (forward), bfill (backward), nearest\n",
    "data.reindex(index=[1,2,3,4,5], method='ffill')\n",
    "\n",
    "# sort data by values of a column(s)\n",
    "data.sort_values(['colname1', 'colname2'], ascending=False, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d3899",
   "metadata": {
    "id": "e30d3899"
   },
   "source": [
    "# ---------- Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e69829",
   "metadata": {
    "id": "38e69829"
   },
   "outputs": [],
   "source": [
    "# column join two dataframes / series | axis=0 row join\n",
    "pd.concat(objs=[df1, df2, df3], axis=1, ignore_index=True, join='outer')\n",
    "\n",
    "# conventional merging\n",
    "pd.merge(left=left_df, right=right_df, on='join_column', how='left/right/outer/inner/cross',\n",
    "         suffixes=['_left', '_right'])\n",
    "\n",
    "# joining from map\n",
    "dct = {'Male': 1, 'Female': 2}\n",
    "df['tip_means_by_sex'] = df['sex'].map(dct)\n",
    "\n",
    "# patch NaNs in df1 with values in df2 (df1, df2 like-indexed)\n",
    "df1.combine_first(df2)\n",
    "\n",
    "# replace non NaNs in df1 with values in df2 (df1, df2 like-indexed)\n",
    "df1.update(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311f0b9",
   "metadata": {
    "id": "2311f0b9",
    "outputId": "27158509-a70a-402e-bdbb-a84e1a2a2473"
   },
   "outputs": [],
   "source": [
    "# left join example:\n",
    "df1 = pd.DataFrame({'col1': ['a', 'b'], 'col2': [1, 2]})\n",
    "df2 = pd.DataFrame({'col1': ['a', 'a', 'b', 'b', 'b'], 'col3': [101, 102, 901, 902, 903]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e51278",
   "metadata": {
    "id": "95e51278",
    "outputId": "9a672586-afce-4737-f3a5-5599be760d9d"
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a5545e",
   "metadata": {
    "id": "14a5545e",
    "outputId": "40ec92f9-7e44-4232-bc50-4867ba08d87c"
   },
   "outputs": [],
   "source": [
    "df1.merge(df2, on='col1', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25b903",
   "metadata": {
    "id": "ec25b903"
   },
   "source": [
    "# ---------- Slice / Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4a531e",
   "metadata": {
    "id": "9b4a531e"
   },
   "outputs": [],
   "source": [
    "# dtypes: int64, float64, bool, datetime64, timedelta64, object, category\n",
    "data.select_dtypes(include=['int64'], exclude=['object'])\n",
    "\n",
    "# .nsmallest\n",
    "data.nlargest(4, 'colname')\n",
    "\n",
    "# label-based: search by row/col labels\n",
    "data.loc[['2017-01-03', '2017-01-05'], ['colname1', 'colname2']]\n",
    "\n",
    "# search by index\n",
    "data.iloc[0:10, 0:2]\n",
    "\n",
    "# get iloc index of column\n",
    "data.columns.get_loc('colname')\n",
    "\n",
    "# random sample: specify <n> or <frac>\n",
    "data.sample(n=3, weights='weights_column', replace=False, axis=0, random_state=42)\n",
    "# randomize\n",
    "data.sample(frac=1).reset_index(inplace=True, drop=True)\n",
    "\n",
    "# filter data where values of colname is in a list\n",
    "data[data['colname'].isin(['A', 'B', 'C'])]\n",
    "\n",
    "# filter data where column name contains string\n",
    "data[data['colname'].str.contains('hello')]\n",
    "\n",
    "# filter by multiple conditions on rows and columns\n",
    "# add '~' to condition as negation, '|' for or\n",
    "data.loc[(data['colname1'] > 0) & ~(df_sales['colname2'] == 100), ['colname3']]\n",
    "\n",
    "\n",
    "# cut by specifying bins: [0,18], (18,40],...\n",
    "pd.cut(x=data.age,\n",
    "       bins=[0, 18, 40, 60, np.infty],\n",
    "       include_lowest=True,\n",
    "       right=True,\n",
    "       labels=['young', 'adult', 'old', 'retired'])\n",
    "\n",
    "# cut by specifying percentile bounds\n",
    "# or number of percentiles: q=10 -> deciles\n",
    "pd.qcut(x=data.age, q=[0.25, 0.5, 0.75, 1], labels=['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d09d9d",
   "metadata": {
    "id": "81d09d9d"
   },
   "source": [
    "# ---------- Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2183e6",
   "metadata": {
    "id": "0b2183e6"
   },
   "outputs": [],
   "source": [
    "data.stack(level=-1) # compresses columns as inner-most index\n",
    "data.unstack(level=-1) # reverses stack\n",
    "\n",
    "# explodes list-like values\n",
    "data.explode(column='colname')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e4737",
   "metadata": {
    "id": "8e8e4737"
   },
   "source": [
    "## pivot / crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa779a0",
   "metadata": {
    "id": "2fa779a0"
   },
   "outputs": [],
   "source": [
    "# pivot\n",
    "# expand multiple rows under 'colname1' as columns; columns times values set of columns\n",
    "data.pivot(index='colname1', columns=['colname2'], values=['colname3', 'colname4'])\n",
    "\n",
    "# pivot table\n",
    "# values: the column to be aggregated\n",
    "data.pivot_table(index=\"colname1\", columns=\"colname2\", values=\"colname3\",\n",
    "                 aggfunc='mean', margins=True)\n",
    "\n",
    "# get proportion by each row\n",
    "pivot_table.div([row1_sum, row2_sum, row3_sum], axis=0)\n",
    "\n",
    "# return cross-tabulated counts/percentages\n",
    "pd.crosstab(data[\"colname1\"], data[\"colname2\"], normalize=True)\n",
    "# with aggfunc\n",
    "pd.crosstab(data[\"colname1\"], data[\"colname2\"],\n",
    "            margins=True, values=data[\"colname3\"], aggfunc=lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e5f5a2",
   "metadata": {
    "id": "98e5f5a2"
   },
   "source": [
    "## group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80593b2",
   "metadata": {
    "id": "f80593b2"
   },
   "outputs": [],
   "source": [
    "# as_index=True makes groups into indexes\n",
    "grouped = data.groupby(['colname1', 'colname2'], as_index=False)\n",
    "\n",
    "grouped.get_group('group_i_name') # get the dataframe of that group, group name is categorical level\n",
    "grouped.groups.keys() # get all group names (keys) | values are indexes\n",
    "[(name, group_data) for (name, group_data) in grouped] # unpack names and groups\n",
    "\n",
    "# compute aggregations\n",
    "grouped['colname3'].mean()\n",
    "grouped['colname3'].agg(['mean', 'std'])\n",
    "\n",
    "\n",
    "# group-by with .agg()\n",
    "(db1.groupby('colname')\n",
    "    .agg({'colname1': ['first', 'last'],\n",
    "          'colname2': ['sum', 'mean', 'count'],\n",
    "          'colname3': lambda x: x.max() - x.min()  # x refers to all rows in each group\n",
    "         })\n",
    ")\n",
    "# with names\n",
    "(data.groupby('colname')\n",
    "     .agg(agg_name1 = ('colname1', 'sum'),\n",
    "          range = ('colname2', lambda x: x.max() - x.min())\n",
    "         )\n",
    ")\n",
    "\n",
    "\n",
    "# custom named function\n",
    "custom_function = lambda x: x\n",
    "custom_function.__name__ = 'func_name'\n",
    "data.agg([custom_function])\n",
    "\n",
    "\n",
    "# group by custom index values\n",
    "df.groupby(lambda x: x.year).sum()\n",
    "\n",
    "# apply transformation within each group\n",
    "data.groupby('colname1').transform(lambda x: x - x.mean())\n",
    "data.groupby('colname1').rolling(window=3)['colname2'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7a00a",
   "metadata": {
    "id": "6ba7a00a"
   },
   "source": [
    "# ---------- Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08328e07",
   "metadata": {
    "id": "08328e07"
   },
   "source": [
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e6339",
   "metadata": {
    "id": "645e6339"
   },
   "outputs": [],
   "source": [
    "# Dataframe & Series:\n",
    "data.shift(-1) # lead (shift backward/right)\n",
    "data.shift(1) # lag (shift forward/left)\n",
    "data.diff(1) # difference between two-elements: i - (i-1), start from i=0\n",
    "data.diff(-1) # difference between two-elements: (i-1) - i, start from i=0\n",
    "\n",
    "# create new column based on existing columns\n",
    "data[\"new colname\"] = data[\"colname1\"] + data[\"colname2\"]\n",
    "\n",
    "\n",
    "# --- handling NaN\n",
    "# drop na values by column; subset=Null for entire dataset\n",
    "data.dropna(subset=[\"colname\"], axis=0, inplace=True)\n",
    "\n",
    "# fill na\n",
    "data.fillna(value=0) # fill all NaN with value\n",
    "data.fillna(value={'colname1': 0, 'colname2': 100}) # fill with dictionary (keys must match colnames)\n",
    "data.fillna(value=data.mean()[['colname1', 'colname2']]) # fill with series (index must match colnames)\n",
    "data.fillna(method=None) # ‘bfill’, ‘ffill’\n",
    "\n",
    "# interpolation\n",
    "# linear, quadratic, cubic\n",
    "data.interpolate(method='linear')\n",
    "\n",
    "# drop columns based on name\n",
    "data.drop(columns=[\"colname1\", \"colname2\"], axis=1, inplace=True)\n",
    "\n",
    "# drop columns based on index\n",
    "data.drop(columns=data.columns[i], axis=1)\n",
    "\n",
    "# drop duplicated rows\n",
    "data.drop_duplicates(subset=[\"colname1\", \"colname2\"], keep={'first', 'last', False})\n",
    "\n",
    "\n",
    "# replace values\n",
    "data.replace(to_replace=[\"yes\", \"no\"], value=[1, 0], inplace=False)\n",
    "\n",
    "# replace with dictionary\n",
    "data.replace({'oldvalue1': 'newvalue1', 'oldvalue2': 'newvalue2'})\n",
    "\n",
    "# replace values with regex\n",
    "data.column.replace(to_replace='^(.)|(.)$', value='_', regex=True)\n",
    "\n",
    "\n",
    "# get dummies\n",
    "pd.get_dummies(data['colname'], prefix=\"table1\", prefix_sep=\"_\", drop_first=False)\n",
    "\n",
    "# returns dataframe of same shape as original, values outside of condition become NaN\n",
    "data.where(data > 0)\n",
    "# or replace those values with 'other'\n",
    "data.where(data > 0, other=-data, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56058625",
   "metadata": {
    "id": "56058625"
   },
   "source": [
    "## apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730bd46",
   "metadata": {
    "id": "d730bd46"
   },
   "outputs": [],
   "source": [
    "# if axis=0, average of top and bottom values for each column\n",
    "# if axis=1, average of leftmost and rightmost values for each row\n",
    "\n",
    "# apply function to each element in data frame\n",
    "data.applymap(func=lambda x: x**2)\n",
    "\n",
    "# creating a new column based on two columns\n",
    "# axis=1: apply function to each row\n",
    "data[['Double_Header', 'Tickets_Sold']].apply(lambda x: x[1] if pd.isna(x[0]) else x[1]/2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf76b1",
   "metadata": {
    "id": "73cf76b1"
   },
   "source": [
    "## pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72533a9",
   "metadata": {
    "id": "e72533a9"
   },
   "outputs": [],
   "source": [
    "def step_1(df, na_subset):\n",
    "    return df.dropna(axis=0, subset=[na_subset])\n",
    "\n",
    "def step_2(df, operation='add', constants=[0,0,0]):\n",
    "    if operation == 'add':\n",
    "        return df.add(constants, axis=1)\n",
    "\n",
    "(data.pipe(step_1, na_subset='region A')\n",
    "     .pipe(step_2, operation='add', constants=[10, 20, 30])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538f832",
   "metadata": {
    "id": "f538f832"
   },
   "source": [
    "## transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b0015",
   "metadata": {
    "id": "7e2b0015"
   },
   "outputs": [],
   "source": [
    "# selective transformation\n",
    "data.transform({'colname1': np.abs,\n",
    "                'colname2': lambda x: x + 1})\n",
    "\n",
    "# apply multiple functions to one column\n",
    "data['colname'].transform([np.abs, lambda x: x + 1])\n",
    "\n",
    "# apply multiple functions to all columns\n",
    "data.transform([np.abs, lambda x: x + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532f455",
   "metadata": {
    "id": "2532f455"
   },
   "source": [
    "## assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d941c",
   "metadata": {
    "id": "a49d941c"
   },
   "outputs": [],
   "source": [
    "(data.query(\"`colname 1` > 0\")\n",
    "     .assign(total=lambda x: x.sum(axis=1),\n",
    "             total_times_10=lambda x: x['total'] * 10)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
