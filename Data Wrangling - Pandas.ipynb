{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1334cd8d",
   "metadata": {
    "id": "1334cd8d"
   },
   "source": [
    "pandas: https://pandas.pydata.org/docs/user_guide/index.html#user-guide\n",
    "\n",
    "pandas DF: https://pandas.pydata.org/docs/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98ede6",
   "metadata": {
    "id": "9b98ede6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d6596a",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    " # Table of Contents  \n",
    "1. [Options](#options)\n",
    "1. [Data Types](#datatypes)\n",
    "    1. [Category](#category)\n",
    "1. [String](#string)\n",
    "    1. [Series.str](#series.str)\n",
    "1. [Dates](#dates)\n",
    "    1. [pd.to_datetime()](#pd.to_datetime())\n",
    "    1. [pd.date_range()](#pd.date_range())\n",
    "    1. [Series.dt](#series.dt)\n",
    "    1. [Time Delta](#timedelta)\n",
    "1. [Input/Output](#input/output)\n",
    "1. [Create DataFrame](#createdataframe)\n",
    "1. [Index / Columns](#indexcolumns)\n",
    "    1. [MultiIndex](#multiindex)\n",
    "1. [Mutability](#mutability)\n",
    "1. [Data Overview](#dataoverview)\n",
    "1. [Math/Stats](#mathstats)\n",
    "1. [Sorting](#sorting)\n",
    "1. [Merging](#merging)\n",
    "1. [Slicing / Filtering](#slicingfiltering)\n",
    "    1. [General](#slicinggeneral)\n",
    "    1. [query()](#query)\n",
    "1. [Transformation](#transform)\n",
    "    1. [Basic](#basic)\n",
    "    1. [Handling missing values](#missingvalues)\n",
    "    1. [apply()](#apply)\n",
    "    1. [pipe()](#pipe)\n",
    "    1. [transform()](#ttransform)\n",
    "    1. [assign()](#assign)\n",
    "1. [Reshaping / Aggregating](#reshaping)\n",
    "    1. [Pivot / Crosstab](#pivotcrosstab)\n",
    "    1. [groupby](#groupby)\n",
    "    1. [Advanced groupby](#advancedgroupby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9795434f",
   "metadata": {
    "id": "9795434f"
   },
   "source": [
    "<a id=\"options\"></a> \n",
    "# ---------- Options ----------\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99b545",
   "metadata": {
    "id": "1f99b545"
   },
   "outputs": [],
   "source": [
    "## describe all options\n",
    "pd.describe_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c1238",
   "metadata": {
    "id": "a09c1238"
   },
   "outputs": [],
   "source": [
    "## show the current value of an option\n",
    "pd.options.display.max_rows\n",
    "# .max_rows(None) .max_columns(None) .precision(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41190c29",
   "metadata": {
    "id": "41190c29"
   },
   "outputs": [],
   "source": [
    "## set an option\n",
    "pd.set_option(\"display.max_rows\", 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b052426",
   "metadata": {},
   "source": [
    "<a id=\"datatypes\"><a/>\n",
    "# ---------- Data Types ----------\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e7d71",
   "metadata": {
    "id": "f86e7d71"
   },
   "outputs": [],
   "source": [
    "## change type for entire dataframe\n",
    "df.astype(int)\n",
    "\n",
    "## change type for particular columns\n",
    "df.astype({'colname1': 'float32', 'colname2': 'str'})\n",
    "\n",
    "## convert to numeric\n",
    "pd.to_numeric(series, errors='coerce')\n",
    "# errors: 'ignore', 'raise', 'coerce'\n",
    "\n",
    "## convert to numpy array / dataframe\n",
    "series.to_numpy() \n",
    "series.to_frame(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e351f",
   "metadata": {
    "id": "eb8e351f",
    "outputId": "b32e5962-1ec1-44fc-8503-af1ec0392b65"
   },
   "outputs": [],
   "source": [
    "## .astype('string') changes np.nan to pd.NA\n",
    "pd.DataFrame([[1.0, 1, pd.NA, np.nan]]).astype('string')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8471449",
   "metadata": {
    "id": "a8471449"
   },
   "source": [
    "<a id=\"category\"><a/>\n",
    "## Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec211ca",
   "metadata": {
    "id": "cec211ca",
    "outputId": "1ba51104-65d2-4b3b-ff1f-f4ff87348c93"
   },
   "outputs": [],
   "source": [
    "## convert values to 'category' type\n",
    "series.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4de13",
   "metadata": {
    "id": "bae4de13",
    "outputId": "ac2619ba-58c6-40ec-9de6-087f48aa4b52"
   },
   "outputs": [],
   "source": [
    "## rename categories\n",
    "## a list, or a dict, or a callable\n",
    "series.cat.rename_categories(['excellent', 'good', 'bad'])\n",
    "\n",
    "## set order of categories\n",
    "series.cat.set_categories(['bad', 'good', 'great'], ordered=True)\n",
    "\n",
    "## reorder\n",
    "series.cat.reorder_categories(['great', 'good', 'bad'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed59182e",
   "metadata": {
    "id": "ed59182e"
   },
   "outputs": [],
   "source": [
    "# .remove_unused_categories()\n",
    "# .remove_categories(['cat1', 'cat2'])\n",
    "# .as_ordered()\n",
    "# .as_unordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091cb00",
   "metadata": {
    "id": "5091cb00"
   },
   "source": [
    "<a id=\"string\"></a> \n",
    "# ---------- String ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c32d682",
   "metadata": {
    "id": "6c32d682"
   },
   "source": [
    "<a id=\"series.str\"></a> \n",
    "## Series.str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e0dbb",
   "metadata": {
    "id": "c54e0dbb",
    "outputId": "c943cb38-2ce1-4151-991b-19fa0101524a"
   },
   "outputs": [],
   "source": [
    "## retrieve i-th character\n",
    "series.str[i]\n",
    "\n",
    "## contains\n",
    "series.str.contains(\"abc\")\n",
    "\n",
    "## replace pattern\n",
    "series.str.replace(pat=' ', repl='-', regex=False)\n",
    "\n",
    "## split string by pattern, new column for each item (up to n columns)\n",
    "series.str.split(pat='', expand=True, n=-1)\n",
    "\n",
    "## extract named groups, creating one column per group\n",
    "string_series.str.extract(r\"(?P<letter>[ab])(?P<digit>\\d)\")\n",
    "\n",
    "## concatenate series into one string value\n",
    "series.str.cat(sep=',', na_rep='-')\n",
    "\n",
    "## concatenate with another equal-length series\n",
    "series.str.cat(series2, sep='_', na_rep='')\n",
    "\n",
    "## concatenate with a equal-length dataframe, joining using index\n",
    "series.str.cat(df, sep='_', na_rep='', join='outer')\n",
    "\n",
    "# .lower() .upper() .len() .strip() .lstrip() .rstrip() \n",
    "# .repeat() .pad()\n",
    "# .isalpha() .isdigit() .islower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06452386",
   "metadata": {
    "id": "06452386"
   },
   "source": [
    "<a id=\"dates\"></a>\n",
    "# ---------- Dates ----------\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b04d65",
   "metadata": {
    "id": "34b04d65"
   },
   "source": [
    "<a id=\"pd.to_datetime()\"></a> \n",
    "## pd.to_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7cc67",
   "metadata": {
    "id": "b3c7cc67",
    "outputId": "adcd3b82-9068-44a8-c4ed-ee1763ec38dd"
   },
   "outputs": [],
   "source": [
    "## returns Timestamp object for 'now'\n",
    "pd.to_datetime('today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0766d54",
   "metadata": {
    "id": "d0766d54",
    "outputId": "8d8dab78-5716-4dce-ddc0-944aac32e0bd"
   },
   "outputs": [],
   "source": [
    "## format list of string dates as DatetimeIndex, each item a Timestamp object\n",
    "pd.to_datetime(['26-03-1997', '20-04-1998'], format=\"%d-%m-%Y\")\n",
    "\n",
    "# %a - abbreviated weekday name | %A - full weekday name\n",
    "# %d - day of month zero padded\n",
    "# %b - abbreviated month name | %B - full month name\n",
    "# %m - month zero padded\n",
    "# %y - year without century zero padded | %Y - year with centure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b832031",
   "metadata": {
    "id": "8b832031"
   },
   "source": [
    "<a id=\"pd.date_range()\"></a> \n",
    "## pd.date_range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154a878",
   "metadata": {
    "id": "c154a878",
    "outputId": "f18e5bfe-4e77-4da3-d645-40fedcbce7c2"
   },
   "outputs": [],
   "source": [
    "## create a range of dates, at fixed intervals\n",
    "## specify start, period, freq\n",
    "## each item a Timestamp object\n",
    "pd.date_range(start='2020-01-01', periods=4, freq='M')\n",
    "\n",
    "## specify start, end, freq\n",
    "pd.date_range(start='2020-01-01', end='2020-12-01', freq='MS')\n",
    "# freq: \"4H\", \"6H\", \"D\", \"W-MON\", \"W-SUN\", \"MS\", \"M\", \"QS\", \"Q\", \"A-JAN\", \"A-DEC\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef76b56",
   "metadata": {
    "id": "6ef76b56"
   },
   "source": [
    "<a id=\"series.dt\"></a> \n",
    "## Series.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621a6f2",
   "metadata": {
    "id": "8621a6f2",
    "outputId": "7d170f6c-46a6-4489-87eb-6b466b4bc609"
   },
   "outputs": [],
   "source": [
    "## get component of datetime\n",
    "series.dt.month_name()\n",
    "# second, minute, hour,\n",
    "# day, dayofweek, dayofyear, day_name(), week, weekofyear, month, month_name(), quarter, year\n",
    "\n",
    "## maps to period\n",
    "series.dt.to_period('Q')\n",
    "# freq: \"4H\", \"6H\", \"D\", \"W-MON\", \"W-SUN\", \"MS\", \"M\", \"QS\", \"Q\", \"A-JAN\", \"A-DEC\"\n",
    "\n",
    "## change date format\n",
    "series.dt.strftime('%d/%m/%Y')\n",
    "\n",
    "## make series time zone aware\n",
    "series.dt.tz_localize('EST')\n",
    "\n",
    "## change time zone aware series to another time zone\n",
    "series.dt.tz_convert('US/Pacific')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e98ec3c",
   "metadata": {
    "id": "7e98ec3c"
   },
   "source": [
    "<a id=\"timedelta\"></a>\n",
    "## Time Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27df3fa",
   "metadata": {
    "id": "c27df3fa",
    "outputId": "22a6fe5f-2ff6-42f6-fd07-efce5c8c1d5d"
   },
   "outputs": [],
   "source": [
    "## difference between two Timestamps\n",
    "## returns Timedelta object\n",
    "time_delta = pd.Timestamp(\"2020/03/24 00:18:48\") - pd.to_datetime(\"2019/03/04 00:12:23\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b2dca0",
   "metadata": {
    "id": "40b2dca0",
    "outputId": "a338a985-0e04-41f1-e0d6-531cff037abf"
   },
   "outputs": [],
   "source": [
    "## extract time component from Timedelta\n",
    "time_delta.days \n",
    "# microseeconds, seconds, total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a0c6d",
   "metadata": {
    "id": "af7a0c6d",
    "outputId": "fe16c3c3-5d1a-48c4-fa79-e7ea85f8f5ea"
   },
   "outputs": [],
   "source": [
    "## subtract Timestamp by Timedelta\n",
    "## absolute time arithmetic\n",
    "pd.to_datetime(\"2020/03/24 00:18:48\") - pd.Timedelta(days=9, weeks=1)\n",
    "# kwargs: years, months, weeks, days, hours, minutes\n",
    "#         seconds, milliseconds, microseconds, nanoseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6174ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## subtract Timestamp by DateOffset\n",
    "## respects calendar arithmetic\n",
    "pd.to_datetime(\"2020/03/24 00:18:48\") - pd.DateOffset(days=9, weeks=1)\n",
    "# kwargs: years, months, weeks, days, hours, minutes\n",
    "#         seconds, milliseconds, microseconds, nanoseconds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32f8d9",
   "metadata": {
    "id": "1f32f8d9"
   },
   "source": [
    "<a id=\"input/output\"><a/>\n",
    "# ---------- Input / Output ----------\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256a5a2",
   "metadata": {
    "id": "5256a5a2"
   },
   "outputs": [],
   "source": [
    "path = (\"C:/Users/mushj/Desktop/WORK/\")\n",
    "\n",
    "## read table\n",
    "data = pd.read_table(path + \"filename.csv\",\n",
    "                     header=3, sep=',', nrows=-1)\n",
    "\n",
    "## .xlsx files\n",
    "data = pd.read_excel(path + \"filename.xlsx\",\n",
    "                     header=3, sheet_name='sheet_name or #')\n",
    "# sheet_name=None (read all sheets)\n",
    "\n",
    "## .csv files\n",
    "data = pd.read_csv(path + \"filename.csv\",\n",
    "                   sep=';', delim_whitespace=False)\n",
    "\n",
    "## writing\n",
    "data.to_csv(\"filename.csv\", index=False)\n",
    "data.to_excel(\"filename.xlsx\")\n",
    "data.to_sql(\"filename.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82507cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## writing to multiple sheets in Excel workbook\n",
    "with pd.ExcelWriter(\"filename.xlsx\",\n",
    "                    date_format=\"YYYY-MM-DD\",\n",
    "                    mode=\"a\", # 'w', 'a'\n",
    "                    engine=\"openpyxl\",\n",
    "                    if_sheet_exists=\"replace\" # ‘error’, ‘new’, ‘replace’, ‘overlay’\n",
    "                   ) as writer:\n",
    "    df1.to_excel(writer, sheet_name=\"Sheet1\")\n",
    "    df2.to_excel(writer, sheet_name=\"Sheet2\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e83035",
   "metadata": {
    "id": "58e83035"
   },
   "source": [
    "<a id=\"createdataframe\"><a/>\n",
    "# ---------- Create DataFrame ----------\n",
    "    \n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1c06c",
   "metadata": {
    "id": "78e1c06c"
   },
   "outputs": [],
   "source": [
    "## from dictionary\n",
    "pd.DataFrame({'col1': [10,20], 'col2': ['a','b']}, index=[1,2])\n",
    "\n",
    "## from nested list\n",
    "pd.DataFrame([[1,2,3], ['a','b','c']], index=[1,2], columns=['col1', 'col2', 'col3'])\n",
    "\n",
    "## from list of dictionaries\n",
    "pd.DataFrame([{'col1': 1, 'col2': 2}, {'col1': 1, 'col3': 3}], index=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6ce1b5",
   "metadata": {
    "id": "3b6ce1b5"
   },
   "source": [
    "<a id=\"indexcolumns\"><a/>\n",
    "# ---------- Index / Columns ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3d7e7e",
   "metadata": {
    "id": "3b3d7e7e"
   },
   "outputs": [],
   "source": [
    "## rename indexes/columns\n",
    "df.columns = ['newcolname1', 'newcolname2', 'newcolname3']\n",
    "df.index = [1,2,3,4,5,6,7]\n",
    "\n",
    "## rename selected indexes/columns\n",
    "df.rename(columns={'oldcolname1': 'newcolname1'},\n",
    "         index={'oldrowname': 'newrowname'})\n",
    "\n",
    "## union indexes: stats union, then sort\n",
    "pd.Index([3,2,1,0]).union(pd.Index([2,3,4,5]))\n",
    "\n",
    "## reset index\n",
    "df.reset_index(drop=True)\n",
    "# drop=True -> don't keep index as column\n",
    "\n",
    "## set a certain variable as index\n",
    "df.set_index(keys='varname', drop=True)\n",
    "\n",
    "## label axis names with list object\n",
    "df.set_axis(labels=['a', 'b', 'c'], axis=1)\n",
    "# axis=0 (row names), axis=1 (colnames)\n",
    "\n",
    "## name series before concatenating to dataframe\n",
    "pd.Series(array, name='new_colname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert single/multi index to series\n",
    "index.to_series(name=\"name\", index=[1,2,3])\n",
    "\n",
    "## repeat index in order\n",
    "index.repeat(repeats=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d5d436",
   "metadata": {},
   "source": [
    "<a id=\"multiindex\"><a/>\n",
    "## MultiIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the following 3 return the same MultiIndex\n",
    "\n",
    "## from arrays\n",
    "pd.MultiIndex.from_arrays([['a', 'a', 'b', 'b'], ['1', '2', '1', '2']],\n",
    "                          names=[\"level1\", \"level2\"])\n",
    "\n",
    "## from tuples\n",
    "pd.MultiIndex.from_tuples([('a', '1'), ('a', '2'), ('b', '1'), ('b', '2')],\n",
    "                          names=[\"level1\", \"level2\"])\n",
    "\n",
    "## cartesian product\n",
    "pd.MultiIndex.from_product([['a', 'b'], ['1', '2']],\n",
    "                           names=[\"level1\", \"level2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "## slice multi-index (must specify value at all levels)\n",
    "df.loc[('a', '1')]\n",
    "\n",
    "## slicing based on a subset of levels\n",
    "df.xs(('value1', 'value2'), level=['level1', 'level3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abe73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get level values\n",
    "## specify integer or level name\n",
    "index.get_level_values(level=0)\n",
    "\n",
    "## flatten index\n",
    "index.to_flat_index()\n",
    "\n",
    "## drop a level of index from dataframe\n",
    "## specify integer or level name\n",
    "df.droplevel(level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd394ec",
   "metadata": {},
   "source": [
    "<a id=\"mutability\"><a/>\n",
    "# ---------- Mutability ----------\n",
    "\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026d31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## changing cell (0,2) will not change all values in column 2\n",
    "## although list multiplication created 10 references to the same list\n",
    "df1 = pd.DataFrame([[0,1,2]]*10, columns=['a','b','c'])\n",
    "df1.iloc[0,2] = 2000\n",
    "\n",
    "## changes the original df, unless copied\n",
    "def func(df):\n",
    "    df = df.copy(deep=True)\n",
    "    df.loc[5,0] = 1000\n",
    "    \n",
    "## df can be modified through df2\n",
    "## i.e. a view is created using .iloc, .loc, or df[\"col\"]\n",
    "df2 = df1.iloc[4:8,0:2].T\n",
    "df2.iloc[1,2] = 1000\n",
    "\n",
    "## a copy is created\n",
    "df2 = df1.loc[df1.index.repeat(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f93438b",
   "metadata": {
    "id": "3f93438b"
   },
   "source": [
    "<a id=\"dataoverview\"><a/>\n",
    "# ---------- Data Overview ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0879160",
   "metadata": {
    "id": "d0879160"
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.columns.values\n",
    "df.index.values\n",
    "df.dtypes\n",
    "df.head(n=5)\n",
    "df.tail(n=5)\n",
    "df.info()\n",
    "\n",
    "## use .equals to compare df with np.nan, because np.nan != np.nan\n",
    "(df * 2).equals(df + df)\n",
    "\n",
    "## descriptive overview with custom percentiles\n",
    "df.describe(percentiles=[0.05, 0.1, 0.25], include=['float64'])\n",
    "\n",
    "## get unique values / counts of unique values\n",
    "df|series.nunique()\n",
    "series.unique()\n",
    "\n",
    "## check duplicates\n",
    "df.duplicated(subset=['colname1', 'colname2'], keep=False) \n",
    "# keep: first, last, False\n",
    "\n",
    "## count value by group\n",
    "df.value_counts([\"colname1\", \"colname2\", \"colname3\"],\n",
    "                normalize=False sort=True, ascending=False)\n",
    "\n",
    "## print value counts for all object variables\n",
    "for col in df.columns.values:\n",
    "    if df[col].dtypes == 'object':\n",
    "        print(df.value_counts(col))\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7973ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check NaNs\n",
    "df.isnull().sum(axis=0)\n",
    "df.notnull().sum(axis=0)\n",
    "df.isna().sum(axis=0)\n",
    "df.notna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dd5097",
   "metadata": {
    "id": "56dd5097"
   },
   "source": [
    "<a id=\"mathstats\"><a/>\n",
    "# ---------- Math/Stat Operations ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead641f",
   "metadata": {
    "id": "8ead641f"
   },
   "outputs": [],
   "source": [
    "## get index of min/max\n",
    "df.idxmax(axis=0)\n",
    "# .idxmin()\n",
    "\n",
    "## --- descriptive statistics\n",
    "# Dataframe & Series:\n",
    "# .count() .sum() .mean() .mad() .median() .min() .max() .mode()\n",
    "# .abs() .prod() .std() .var() .sem() .skew() .kurt() .quantile(0.75)\n",
    "# .cumsum() .cumprod() .cummin() .cummax()\n",
    "# .pct_change(periods=1)\n",
    "\n",
    "## covariance / correlation\n",
    "series1.cov(series2)  \n",
    "df.cov()\n",
    "df.corr(method='')\n",
    "\n",
    "## standard error of mean\n",
    "df.sem(axis=0, numeric_only=True, skipna=True)\n",
    "\n",
    "## autocorrelation\n",
    "series.autocorr(lag=5)\n",
    "\n",
    "## --- arithmetic\n",
    "# .add() .sub() .mul() .div() .floordiv() .mod() .pow()\n",
    "df.sub([1, 2, 3], axis=1, fill_value=None) # broadcast rowwise\n",
    "\n",
    "## rolling window\n",
    "series.rolling(window=4, center=False, closed=None).mean()\n",
    "# closed: left, right, both, neither\n",
    "\n",
    "## rolling with custom function: e.g. Mean Absolute Deviation from mean within window\n",
    "series.rolling(window=4).apply(lambda x: np.abs(x - x.mean()).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3889df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cut by specifying bins: [0,18], (18,40],...\n",
    "pd.cut(x=series,\n",
    "       bins=[0, 18, 40, 60, np.infty],\n",
    "       include_lowest=True,\n",
    "       right=True,\n",
    "       labels=[\"A\", \"B\", \"C\", \"D\"])\n",
    "\n",
    "## cut by specifying percentile bounds\n",
    "## or number of percentiles: q=10 -> deciles\n",
    "pd.qcut(x=series, q=[0.25, 0.5, 0.75, 1], labels=['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd846126",
   "metadata": {
    "id": "dd846126"
   },
   "source": [
    "<a id=\"sorting\"><a/>\n",
    "# ---------- Sorting ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce490e2c",
   "metadata": {
    "id": "ce490e2c"
   },
   "outputs": [],
   "source": [
    "## reorder dataframe based on new index/column order\n",
    "df.reindex([4, 2, 1, 3], axis=0)\n",
    "df.reindex(index=[4, 2, 1, 3], columns=['C', 'A', 'B'])\n",
    "\n",
    "## if there are new indexes, fill with\n",
    "## ffill (forward), bfill (backward), nearest\n",
    "df.reindex(index=[1,2,3,4,5], method='ffill')\n",
    "\n",
    "## sort data by values of a column(s)\n",
    "df.sort_values(['colname1', 'colname2'], ascending=False, axis=0)\n",
    "\n",
    "## sort data by a level of multiindex\n",
    "df.sort_index(level=[1,0], ascending=False)\n",
    "\n",
    "\n",
    "## create a column ranking values\n",
    "df.rank(method=\"dense\", ascending=True, na_option=\"keep\", pct=False, axis=0)\n",
    "# method: 'average', 'min', 'max', 'first', 'dense'\n",
    "# na_option: 'keep', 'top', 'bottom'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d3899",
   "metadata": {
    "id": "e30d3899"
   },
   "source": [
    "<a id=\"merging\"><a/>\n",
    "# ---------- Merging ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e69829",
   "metadata": {
    "id": "38e69829"
   },
   "outputs": [],
   "source": [
    "## concatenate two dataframes / series row-wise or column-wise\n",
    "## based on matching index\n",
    "pd.concat(objs=[df1, df2, df3], axis=1, ignore_index=True, join='outer')\n",
    "\n",
    "## joining\n",
    "pd.merge(left=left_df, right=right_df, \n",
    "         left_index=True, right_on='join_column', \n",
    "         how='left/right/outer/inner/cross',\n",
    "         suffixes=['_left', '_right'])\n",
    "\n",
    "## joining from map\n",
    "dct = {'Male': 1, 'Female': 2}\n",
    "df['Gender'].map(dct)\n",
    "\n",
    "## patch NaNs in df1 with values in df2 (df1, df2 like-indexed)\n",
    "df1.combine_first(df2)\n",
    "\n",
    "## replace non NaNs in df1 with values in df2 (df1, df2 like-indexed)\n",
    "df1.update(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25b903",
   "metadata": {
    "id": "ec25b903"
   },
   "source": [
    "<a id=\"slicingfiltering\"><a/>\n",
    "# ---------- Slicing / Filtering ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d2aa7",
   "metadata": {},
   "source": [
    "<a id=\"slicinggeneral\"><a/>\n",
    "## General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4a531e",
   "metadata": {
    "id": "9b4a531e"
   },
   "outputs": [],
   "source": [
    "## select columns of certain dtypes\n",
    "df.select_dtypes(include=['int64'], exclude=['object'])\n",
    "# dtypes: int64, float64, bool, datetime64, timedelta64, object, category\n",
    "\n",
    "## return rows that are the n-th largest \n",
    "df.nlargest(n, [\"col1\", \"col2\"])\n",
    "# .nsmallest\n",
    "\n",
    "## label-based: search by row/col labels\n",
    "df.loc[['2017-01-03', '2017-01-05'], ['colname1', 'colname2']]\n",
    "\n",
    "## search by index\n",
    "df.iloc[0:10, 0:2]\n",
    "\n",
    "## get position of column\n",
    "df.columns.get_loc('colname')\n",
    "\n",
    "## random sample: specify <n> or <frac>\n",
    "df.sample(n=3, weights='weights_column', replace=False, axis=0, random_state=42)\n",
    "\n",
    "## randomize row order\n",
    "df.sample(frac=1).reset_index(inplace=True, drop=True)\n",
    "\n",
    "## filter data where values of colname is in a list\n",
    "df[df['colname'].isin(['A', 'B', 'C'])]\n",
    "\n",
    "## filter by multiple conditions on rows and columns\n",
    "## add '~' to condition as negation, '|' for or\n",
    "df.loc[(df['colname1'] > 0) & ~(df['colname2'] == 100), ['colname3']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## iterate through rows\n",
    "for i,row in df.iterrows():\n",
    "    print(i, row[\"col1\"], row[\"col2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588ad7c",
   "metadata": {},
   "source": [
    "<a id=\"query\"><a/>\n",
    "## query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd087168",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference a variable\n",
    "df.query(\"col_name >= @var\")\n",
    "\n",
    "## multiple filters\n",
    "df.query(\"col_name == 'abc' & col_name == 'xyz'\")\n",
    "\n",
    "## column name with space\n",
    "df.query(\"`col name` < 1\")\n",
    "\n",
    "## operations\n",
    "df.query(\"col_name != 1 + 2\")\n",
    "\n",
    "## reference other columns\n",
    "df.query(\"col_name1 > (col_name2 + col_name3) / 2\")\n",
    "\n",
    "## .isin()\n",
    "df.query(\"`col name`.isin([1,2,3])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7a00a",
   "metadata": {
    "id": "6ba7a00a"
   },
   "source": [
    "<a id=\"transform\"><a/>\n",
    "# ---------- Transform ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08328e07",
   "metadata": {
    "id": "08328e07"
   },
   "source": [
    "<a id=\"basic\"><a/>\n",
    "## Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e6339",
   "metadata": {
    "id": "645e6339"
   },
   "outputs": [],
   "source": [
    "## create new column based on existing columns\n",
    "df[\"new colname\"] = df[\"colname1\"] + df[\"colname2\"]\n",
    "\n",
    "## replace multiple columns at once\n",
    "df[[\"A_new\", \"B_new\", \"C_new\"]] = df[[\"A\", \"B\", \"C\"]].values * df[\"D\"].values.reshape(-1,1)\n",
    "\n",
    "## get dummies\n",
    "pd.get_dummies(df|series, prefix=\"prefix\", prefix_sep=\"_\", drop_first=False)\n",
    "\n",
    "## shifting\n",
    "df|series.shift(-1) # shift backward [a,b,c] -> [b,c,nan]\n",
    "df|series.shift(1) # shift forward [a,b,c] -> [nan,a,b]\n",
    "\n",
    "## difference\n",
    "df|series.diff(-1) # e_i = i - (i+1), starting from i=0\n",
    "df|series.diff(1) # e_i = i - (i+1), starting from i=1\n",
    "\n",
    "## drop columns based on name\n",
    "df.drop(columns=[\"colname1\", \"colname2\"], axis=1)\n",
    "\n",
    "## drop duplicated rows\n",
    "df.drop_duplicates(subset=[\"colname1\", \"colname2\"], keep=\"first\")\n",
    "# keep = \"first\", \"last\", False\n",
    "\n",
    "## replace values\n",
    "df.replace(to_replace=[\"yes\", \"no\"], value=[1, 0])\n",
    "\n",
    "## replace with dictionary\n",
    "df.replace({'oldvalue1': 'newvalue1', 'oldvalue2': 'newvalue2'})\n",
    "\n",
    "## replace values with regex\n",
    "df.column.replace(to_replace='^(.)|(.)$', value='_', regex=True)\n",
    "\n",
    "## returns dataframe of same shape as original, values outside of condition become NaN\n",
    "df.where(df > 0)\n",
    "\n",
    "## replace those values with 'other'\n",
    "df.where(df > 0, other=-df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0b996",
   "metadata": {},
   "source": [
    "<a id=\"missingvalues\"><a/>\n",
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop na values by column; subset=Null for entire dataset\n",
    "df.dropna(subset=[\"col1\", \"col2\"], axis=0)\n",
    "\n",
    "## fill na\n",
    "df.fillna(value=0) # fill all NaN with value\n",
    "df.fillna(value={'col1': 0, 'col2': 100}) # fill with dictionary (keys must match column names)\n",
    "df.fillna(value=df.mean()[['col1', 'col2']]) # fill with series (index = column names, mapping to values)\n",
    "df.fillna(method=None) # ‘bfill’, ‘ffill’\n",
    "df.bfill()\n",
    "df.ffill()\n",
    "\n",
    "## interpolation of NaN values\n",
    "df.interpolate(method='linear', axis=0)\n",
    "# 'nearest', 'zero', 'slinear', 'quadratic', 'cubic', 'spline', 'polynomial'\n",
    "# axis=0: across rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56058625",
   "metadata": {
    "id": "56058625"
   },
   "source": [
    "<a id=\"apply\"><a/>\n",
    "## apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730bd46",
   "metadata": {
    "id": "d730bd46"
   },
   "outputs": [],
   "source": [
    "## apply function to each element in data frame\n",
    "df.applymap(func=lambda x: x**2)\n",
    "\n",
    "## apply function\n",
    "## reference two columns by index\n",
    "df[[\"col1\", \"col2\"]].apply(lambda x: x.iloc[1] if pd.isna(x.iloc[0]) else x.iloc[1]/2, axis=1)\n",
    "# axis=1: apply function to each row (across columns)\n",
    "\n",
    "## reference columns by name\n",
    "df.apply(lambda x: x[\"col1\"] if pd.isna(x[\"col2\"]) else x[\"col1\"]/2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cf76b1",
   "metadata": {
    "id": "73cf76b1"
   },
   "source": [
    "<a id=\"pipe\"><a/>\n",
    "## pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72533a9",
   "metadata": {
    "id": "e72533a9"
   },
   "outputs": [],
   "source": [
    "## chaining functions with arguments\n",
    "## each function must take in and return a dataframe\n",
    "def step_1(df, na_subset):\n",
    "    return df.dropna(axis=0, subset=[na_subset])\n",
    "\n",
    "def step_2(df, operation='add', constants=[0,0,0]):\n",
    "    if operation == 'add':\n",
    "        return df.add(constants, axis=1)\n",
    "\n",
    "(df.pipe(step_1, na_subset='region A')\n",
    "   .pipe(step_2, operation='add', constants=[10, 20, 30])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538f832",
   "metadata": {
    "id": "f538f832"
   },
   "source": [
    "<a id=\"ttransform\"><a/>\n",
    "## transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2b0015",
   "metadata": {
    "id": "7e2b0015"
   },
   "outputs": [],
   "source": [
    "## selective transformation\n",
    "## returns a df with a column for each transformation\n",
    "df.transform({'colname1': np.abs,\n",
    "              'colname2': lambda x: x + 1})\n",
    "\n",
    "## apply multiple functions to one column\n",
    "## returns a df with a column for each transformation\n",
    "df['colname'].transform([np.abs, lambda x: x + 1])\n",
    "\n",
    "## apply multiple functions to all columns\n",
    "df.transform([np.abs, lambda x: x + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f347439",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby().transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532f455",
   "metadata": {
    "id": "2532f455"
   },
   "source": [
    "<a id=\"assign\"><a/>\n",
    "## assign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d941c",
   "metadata": {
    "id": "a49d941c"
   },
   "outputs": [],
   "source": [
    "## create two new columns (column names as arguments)\n",
    "df.assign(total=lambda x: x.sum(axis=1),\n",
    "          total_times_10=lambda x: x['total'] * 10)\n",
    "\n",
    "## create two new columns with dictionary\n",
    "df.assign(**{\"var\": lambda x: x, \"var2\": lambda x: x})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a84a3",
   "metadata": {},
   "source": [
    "## Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60da614",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d09d9d",
   "metadata": {
    "id": "81d09d9d"
   },
   "source": [
    "<a id=\"reshaping\"><a/>\n",
    "# ---------- Reshaping / Aggregating ----------\n",
    "[Table of Contents](#0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2183e6",
   "metadata": {
    "id": "0b2183e6"
   },
   "outputs": [],
   "source": [
    "## unpivot all columns, creating a new level of index\n",
    "df.stack(level=-1)\n",
    "\n",
    "## reverses stack: pivots a level of index as columns\n",
    "df.unstack(level=-1)\n",
    "\n",
    "## explodes a column of arrays into rows (each item taking a row),\n",
    "## repeating values of other columns\n",
    "df.explode(column='colname')\n",
    "\n",
    "## unpivot\n",
    "df.melt(id_vars=[\"col1\", \"col2\"], value_vars=[\"col3\", \"col4\"],\n",
    "        var_name=\"variable\", value_name=\"value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e4737",
   "metadata": {
    "id": "8e8e4737"
   },
   "source": [
    "<a id=\"pivotcrosstab\"><a/>\n",
    "## pivot / crosstab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa779a0",
   "metadata": {
    "id": "2fa779a0"
   },
   "outputs": [],
   "source": [
    "## pivot: without aggregation\n",
    "## creates a cartesian product space, with NaNs if no value\n",
    "df.pivot(index=[\"col1\", \"col2\"], columns=[\"col3\", \"col4\"], values=[\"col5\", \"col6\"])\n",
    "\n",
    "## pivot: with aggregation\n",
    "df.pivot_table(index=\"colname1\", columns=\"colname2\", values=\"colname3\",\n",
    "               aggfunc='mean', margins=True)\n",
    "\n",
    "## return cross-tabulated counts/percentages\n",
    "## creates a cartesian product space\n",
    "pd.crosstab(series1, series2, normalize=True)\n",
    "\n",
    "## with aggfunc\n",
    "pd.crosstab(df[\"colname1\"], df[\"colname2\"],\n",
    "            margins=True, values=df[\"colname3\"], \n",
    "            aggfunc=lambda x: np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e5f5a2",
   "metadata": {
    "id": "98e5f5a2"
   },
   "source": [
    "<a id=\"groupby\"><a/>\n",
    "## group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80593b2",
   "metadata": {
    "id": "f80593b2"
   },
   "outputs": [],
   "source": [
    "## group\n",
    "grouped = df.groupby(['colname1', 'colname2'], as_index=False)\n",
    "# as_index=True makes groups into indexes\n",
    "\n",
    "## retrieve groups\n",
    "grouped.groups.keys() # get all group names (keys)\n",
    "grouped.get_group('group_i_name')\n",
    "[(name, group_data) for (name, group_data) in grouped] # unpack names and groups\n",
    "\n",
    "## compute aggregations\n",
    "df.groupby(\"group_var\")['colname'].mean()\n",
    "df.groupby(\"group_var\")['colname'].agg(['mean', 'std'])\n",
    "df.groupby(\"group_var\")[\"colname\"].apply(list) # collect list\n",
    "df.groupby(\"group_var\")[\"colname\"].apply(set) # collect set\n",
    "\n",
    "## group-by with .agg()\n",
    "(df.groupby(\"group_var\")\n",
    "   .agg({'colname1': ['first', 'last'],\n",
    "         'colname2': ['sum', 'mean', 'count'],\n",
    "         'colname3': lambda x: x.max() - x.min()  # x refers to all rows in each group\n",
    "        })\n",
    ")\n",
    "\n",
    "## with names\n",
    "(df.groupby(\"group_var\")\n",
    "   .agg(col_sum = ('colname1', 'sum'),\n",
    "        col_range = ('colname2', lambda x: x.max() - x.min())\n",
    "       )\n",
    ")\n",
    "\n",
    "## custom named function\n",
    "custom_function = lambda x: x\n",
    "custom_function.__name__ = 'func_name'\n",
    "df.agg([custom_function])\n",
    "\n",
    "\n",
    "## group by custom index values\n",
    "df.groupby(lambda x: x.year).sum()\n",
    "\n",
    "## group by other values\n",
    "df.groupby(df2[\"colname\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dee8ce",
   "metadata": {},
   "source": [
    "<a id=\"advancedgroupby\"><a/>\n",
    "## Advanced group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137190b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rank within groups\n",
    "df.groupby(\"group_var\").rank()\n",
    "\n",
    "## apply transformation within each group\n",
    "df.groupby(\"group_var\").transform(lambda x: x - x.mean())\n",
    "\n",
    "## rolling window\n",
    "df.groupby(\"group_var\").rolling(window=3)['colname'].mean()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
